{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from coperception.datasets import V2XSimDet\n",
    "from coperception.configs import Config, ConfigGlobal\n",
    "from coperception.utils.CoDetModule import *\n",
    "from coperception.utils.loss import *\n",
    "from coperception.models.det import *\n",
    "from coperception.utils import AverageMeter\n",
    "from coperception.utils.data_util import apply_pose_noise\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    pdb.set_trace()\n",
    "    config = Config(\"train\", binary=True, only_det=True)\n",
    "    config_global = ConfigGlobal(\"train\", binary=True, only_det=True)\n",
    "\n",
    "    num_epochs = args.nepoch\n",
    "    need_log = args.log\n",
    "    num_workers = args.nworker\n",
    "    start_epoch = 1\n",
    "    batch_size = args.batch_size\n",
    "    compress_level = args.compress_level\n",
    "    auto_resume_path = args.auto_resume_path\n",
    "    pose_noise = args.pose_noise\n",
    "    only_v2i = args.only_v2i\n",
    "\n",
    "    # Specify gpu device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_num = torch.cuda.device_count()\n",
    "    print(\"device number\", device_num)\n",
    "\n",
    "    if args.com == \"upperbound\":\n",
    "        flag = \"upperbound\"\n",
    "    elif args.com == \"when2com\" and args.warp_flag:\n",
    "        flag = \"when2com_warp\"\n",
    "    elif args.com in [\n",
    "        \"lowerbound\",\n",
    "        \"v2v\",\n",
    "        \"disco\",\n",
    "        \"sum\",\n",
    "        \"mean\",\n",
    "        \"max\",\n",
    "        \"cat\",\n",
    "        \"agent\",\n",
    "        \"when2com\",\n",
    "    ]:\n",
    "        flag = args.com\n",
    "    else:\n",
    "        raise ValueError(f\"com: {args.com} is not supported\")\n",
    "\n",
    "    config.flag = flag\n",
    "\n",
    "    num_agent = args.num_agent\n",
    "    # agent0 is the RSU\n",
    "    agent_idx_range = range(num_agent) if args.rsu else range(1, num_agent)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    training_dataset1 = V2XSimDet(\n",
    "        dataset_roots=[f\"/2211041005/det_shujuji/v2x-sim5/train/agent{i}\" for i in agent_idx_range],\n",
    "        config=config,\n",
    "        config_global=config_global,\n",
    "        split=\"train\",\n",
    "        bound=\"upperbound\" if args.com == \"upperbound\" else \"lowerbound\",\n",
    "        kd_flag=args.kd_flag,\n",
    "        rsu=args.rsu,\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     training_dataset2 = V2XSimDet(\n",
    "#         dataset_roots=[f\"/2211041005/det_shujuji/v2x-sim4/train/agent{i}\" for i in agent_idx_range],\n",
    "#         config=config,\n",
    "#         config_global=config_global,\n",
    "#         split=\"train\",\n",
    "#         bound=\"upperbound\" if args.com == \"upperbound\" else \"lowerbound\",\n",
    "#         kd_flag=args.kd_flag,\n",
    "#         rsu=args.rsu,\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     training_dataset3 = V2XSimDet(\n",
    "#         dataset_roots=[f\"/2211041005/det_shujuji/v2x-sim3/train/agent{i}\" for i in agent_idx_range],\n",
    "#         config=config,\n",
    "#         config_global=config_global,\n",
    "#         split=\"train\",\n",
    "#         bound=\"upperbound\" if args.com == \"upperbound\" else \"lowerbound\",\n",
    "#         kd_flag=args.kd_flag,\n",
    "#         rsu=args.rsu,\n",
    "#     )    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     training_dataset3 = V2XSimDet(\n",
    "#         dataset_roots=[f\"/2211041005/det_shujuji/v2x-sim5/train/agent{i}\" for i in agent_idx_range],\n",
    "#         config=config,\n",
    "#         config_global=config_global,\n",
    "#         split=\"train\",\n",
    "#         bound=\"upperbound\" if args.com == \"upperbound\" else \"lowerbound\",\n",
    "#         kd_flag=args.kd_flag,\n",
    "#         rsu=args.rsu,\n",
    "#     )\n",
    "        \n",
    "#     training_data_loader0 = DataLoader(\n",
    "#         training_dataset2,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         num_workers=num_workers,  \n",
    "#     )\n",
    "    \n",
    "#     training_data_loader1 = DataLoader(\n",
    "#         training_dataset3,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         num_workers=num_workers,  \n",
    "#     )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     N1 = len(training_dataset2)\n",
    "#     sample_size = int(N1 * 0.02)\n",
    "#     sample_indices = random.sample(range(N1), sample_size)\n",
    "#     new_dataset2 = [training_dataset2[i] for i in sample_indices]\n",
    "    \n",
    "#     N2 = len(training_dataset3)\n",
    "#     sample_size = int(N2 * 0.02)\n",
    "#     sample_indices = random.sample(range(N2), sample_size)\n",
    "#     new_dataset3 = [training_dataset3[j] for j in sample_indices]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     combined_training_dataset = ConcatDataset([training_dataset1, new_dataset2,new_dataset3])\n",
    "    \n",
    "    training_data_loader = DataLoader(\n",
    "        training_dataset1,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,  \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     training_data_loader = DataLoader(\n",
    "#         training_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers\n",
    "#     )\n",
    "    print(\"Training dataset size:\", len(training_data_loader))\n",
    "\n",
    "    logger_root = args.logpath if args.logpath != \"\" else \"logs\"\n",
    "\n",
    "    if not args.rsu:\n",
    "        num_agent -= 1\n",
    "\n",
    "    if flag == \"lowerbound\" or flag == \"upperbound\":\n",
    "        model = FaFNet(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "        )\n",
    "    elif flag == \"when2com\" or flag == \"when2com_warp\":\n",
    "        model = When2com(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            warp_flag=args.warp_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"v2v\":\n",
    "        model = V2VNet(\n",
    "            config,\n",
    "            gnn_iter_times=args.gnn_iter_times,\n",
    "            layer=args.layer,\n",
    "            layer_channel=256,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"disco\":\n",
    "        model = DiscoNet(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"sum\":\n",
    "        model = SumFusion(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"mean\":\n",
    "        model = MeanFusion(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"max\":\n",
    "        model = MaxFusion(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"cat\":\n",
    "        model = CatFusion(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "    elif flag == \"agent\":\n",
    "        model = AgentWiseWeightedFusion(\n",
    "            config,\n",
    "            layer=args.layer,\n",
    "            kd_flag=args.kd_flag,\n",
    "            num_agent=num_agent,\n",
    "            compress_level=compress_level,\n",
    "            only_v2i=only_v2i,\n",
    "        )\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    criterion = {\n",
    "        \"cls\": SoftmaxFocalClassificationLoss(),\n",
    "        \"loc\": WeightedSmoothL1LocalizationLoss(),\n",
    "    }\n",
    "\n",
    "    if args.kd_flag == 1:\n",
    "        teacher = TeacherNet(config)\n",
    "        teacher = nn.DataParallel(teacher)\n",
    "        teacher = teacher.to(device)\n",
    "        faf_module = FaFModule(\n",
    "            model, teacher, config, optimizer, criterion, args.kd_flag\n",
    "        )\n",
    "        checkpoint_teacher = torch.load(args.resume_teacher)\n",
    "        start_epoch_teacher = checkpoint_teacher[\"epoch\"]\n",
    "        faf_module.teacher.load_state_dict(checkpoint_teacher[\"model_state_dict\"],False)\n",
    "        print(\n",
    "            \"Load teacher model from {}, at epoch {}\".format(\n",
    "                args.resume_teacher, start_epoch_teacher\n",
    "            )\n",
    "        )\n",
    "        faf_module.teacher.eval()\n",
    "    else:\n",
    "        faf_module = FaFModule(model, model, config, optimizer, criterion, args.kd_flag)\n",
    "\n",
    "    rsu_path = \"with_rsu\" if args.rsu else \"no_rsu\"\n",
    "    model_save_path = check_folder(logger_root)\n",
    "    model_save_path = check_folder(os.path.join(model_save_path, flag))\n",
    "\n",
    "    if args.rsu:\n",
    "        model_save_path = check_folder(os.path.join(model_save_path, \"with_rsu\"))\n",
    "    else:\n",
    "        model_save_path = check_folder(os.path.join(model_save_path, \"no_rsu\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(model_save_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # check if there is valid check point file\n",
    "    has_valid_pth = False\n",
    "    for pth_file in os.listdir(os.path.join(auto_resume_path, f\"{flag}/{rsu_path}\")):\n",
    "        if pth_file.startswith(\"epoch_\") and pth_file.endswith(\".pth\"):\n",
    "            has_valid_pth = True\n",
    "            break\n",
    "\n",
    "    if not has_valid_pth:\n",
    "        print(\n",
    "            f\"No valid check point file in {auto_resume_path} dir, weights not loaded.\"\n",
    "        )\n",
    "        auto_resume_path = \"\"\n",
    "\n",
    "    if args.resume == \"\" and auto_resume_path == \"\":\n",
    "        log_file_name = os.path.join(model_save_path, \"log.txt\")\n",
    "        saver = open(log_file_name, \"w\")\n",
    "        saver.write(\"GPU number: {}\\n\".format(torch.cuda.device_count()))\n",
    "        saver.flush()\n",
    "\n",
    "        # Logging the details for this experiment\n",
    "        saver.write(\"command line: {}\\n\".format(\" \".join(sys.argv[0:])))\n",
    "        saver.write(args.__repr__() + \"\\n\\n\")\n",
    "        saver.flush()\n",
    "    else:\n",
    "        if auto_resume_path != \"\":\n",
    "            model_save_path = os.path.join(auto_resume_path, f\"{flag}/{rsu_path}\")\n",
    "        else:\n",
    "            model_save_path = args.resume[: args.resume.rfind(\"/\")]\n",
    "\n",
    "        print(f\"model save path: {model_save_path}\")\n",
    "\n",
    "        log_file_name = os.path.join(model_save_path, \"log.txt\")\n",
    "\n",
    "        if os.path.exists(log_file_name):\n",
    "            saver = open(log_file_name, \"a\")\n",
    "        else:\n",
    "            os.makedirs(model_save_path, exist_ok=True)\n",
    "            saver = open(log_file_name, \"w\")\n",
    "\n",
    "        saver.write(\"GPU number: {}\\n\".format(torch.cuda.device_count()))\n",
    "        saver.flush()\n",
    "\n",
    "        # Logging the details for this experiment\n",
    "        saver.write(\"command line: {}\\n\".format(\" \".join(sys.argv[1:])))\n",
    "        saver.write(args.__repr__() + \"\\n\\n\")\n",
    "        saver.flush()\n",
    "\n",
    "        if auto_resume_path != \"\":\n",
    "            list_of_files = glob.glob(f\"{model_save_path}/*.pth\")\n",
    "            latest_pth = max(list_of_files, key=os.path.getctime)\n",
    "            checkpoint = torch.load(latest_pth)\n",
    "        else:\n",
    "            checkpoint = torch.load(args.resume)\n",
    "\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        faf_module.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        faf_module.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        faf_module.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "\n",
    "        print(\"Load model from {}, at epoch {}\".format(args.resume, start_epoch - 1))\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        lr = faf_module.optimizer.param_groups[0][\"lr\"]\n",
    "        print(\"Epoch {}, learning rate {}\".format(epoch, lr))\n",
    "\n",
    "        if need_log:\n",
    "            saver.write(\"epoch: {}, lr: {}\\t\".format(epoch, lr))\n",
    "            saver.flush()\n",
    "\n",
    "        running_loss_disp = AverageMeter(\"Total loss\", \":.6f\")\n",
    "        running_loss_class = AverageMeter(\n",
    "            \"classification Loss\", \":.6f\"\n",
    "        )  # for cell classification error\n",
    "        running_loss_loc = AverageMeter(\n",
    "            \"Localization Loss\", \":.6f\"\n",
    "        )  # for state estimation error\n",
    "        running_grads = AverageMeter(\"grads\",\":.2f\")\n",
    "        faf_module.model.train()\n",
    "\n",
    "        t = tqdm(training_data_loader)\n",
    "        for sample in t:\n",
    "            (\n",
    "                padded_voxel_point_list,  # voxelized point cloud for individual agent\n",
    "                padded_voxel_points_teacher_list,  # fused voxelized point cloud for all agents (multi-view)\n",
    "                label_one_hot_list,  # one hot labels\n",
    "                reg_target_list,  # regression targets\n",
    "                reg_loss_mask_list,\n",
    "                anchors_map_list,  # anchor boxes\n",
    "                vis_maps_list,\n",
    "                target_agent_id_list,\n",
    "                num_agent_list,  # e.g. 6 agent in current scene: [6,6,6,6,6,6], 5 agent in current scene: [5,5,5,5,5,0]\n",
    "                trans_matrices_list,  # matrix for coordinate transformation. e.g. [batch_idx, j, i] ==> transformation matrix to transfer from agent i to j\n",
    "            ) = zip(*sample)\n",
    "\n",
    "            trans_matrices = torch.stack(tuple(trans_matrices_list), 1)\n",
    "            target_agent_id = torch.stack(tuple(target_agent_id_list), 1)\n",
    "            num_all_agents = torch.stack(tuple(num_agent_list), 1)\n",
    "\n",
    "            # add pose noise\n",
    "            if pose_noise > 0:\n",
    "                apply_pose_noise(pose_noise, trans_matrices)\n",
    "\n",
    "            if not args.rsu:\n",
    "                num_all_agents -= 1\n",
    "\n",
    "            if flag == \"upperbound\":\n",
    "                padded_voxel_point = torch.cat(\n",
    "                    tuple(padded_voxel_points_teacher_list), 0\n",
    "                )\n",
    "            else:\n",
    "                padded_voxel_point = torch.cat(tuple(padded_voxel_point_list), 0)\n",
    "\n",
    "            label_one_hot = torch.cat(tuple(label_one_hot_list), 0)\n",
    "            reg_target = torch.cat(tuple(reg_target_list), 0)\n",
    "            reg_loss_mask = torch.cat(tuple(reg_loss_mask_list), 0)\n",
    "            anchors_map = torch.cat(tuple(anchors_map_list), 0)\n",
    "            vis_maps = torch.cat(tuple(vis_maps_list), 0)\n",
    "\n",
    "            data = {\n",
    "                \"bev_seq\": padded_voxel_point.to(device),\n",
    "                \"labels\": label_one_hot.to(device),\n",
    "                \"reg_targets\": reg_target.to(device),\n",
    "                \"anchors\": anchors_map.to(device),\n",
    "                \"reg_loss_mask\": reg_loss_mask.to(device).type(dtype=torch.bool),\n",
    "                \"vis_maps\": vis_maps.to(device),\n",
    "                \"target_agent_ids\": target_agent_id.to(device),\n",
    "                \"num_agent\": num_all_agents.to(device),\n",
    "                \"trans_matrices\": trans_matrices,\n",
    "            }\n",
    "\n",
    "            if args.kd_flag == 1:\n",
    "                padded_voxel_points_teacher = torch.cat(\n",
    "                    tuple(padded_voxel_points_teacher_list), 0\n",
    "                )\n",
    "                data[\"bev_seq_teacher\"] = padded_voxel_points_teacher.to(device)\n",
    "                data[\"kd_weight\"] = args.kd_weight\n",
    "\n",
    "            loss, cls_loss, loc_loss,grads = faf_module.step(\n",
    "                data, batch_size, num_agent=num_agent\n",
    "            )\n",
    "            running_loss_disp.update(loss)\n",
    "            running_loss_class.update(cls_loss)\n",
    "            running_loss_loc.update(loc_loss)\n",
    "\n",
    "            if np.isnan(loss) or np.isnan(cls_loss) or np.isnan(loc_loss):\n",
    "                print(f\"Epoch {epoch}, loss is nan: {loss}, {cls_loss} {loc_loss}\")\n",
    "                sys.exit()\n",
    "\n",
    "            t.set_description(\"Epoch {},     lr {}\".format(epoch, lr))\n",
    "            t.set_postfix(\n",
    "                cls_loss=running_loss_class.avg, loc_loss=running_loss_loc.avg\n",
    "            )\n",
    "\n",
    "        faf_module.scheduler.step()\n",
    "\n",
    "        # save model\n",
    "        if need_log:\n",
    "            saver.write(\n",
    "                \"{}\\t{}\\t{}\\n\".format(\n",
    "                    running_loss_disp, running_loss_class, running_loss_loc\n",
    "                )\n",
    "            )\n",
    "            saver.flush()\n",
    "            if config.MGDA:\n",
    "                save_dict = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"encoder_state_dict\": faf_module.encoder.state_dict(),\n",
    "                    \"optimizer_encoder_state_dict\": faf_module.optimizer_encoder.state_dict(),\n",
    "                    \"scheduler_encoder_state_dict\": faf_module.scheduler_encoder.state_dict(),\n",
    "                    \"head_state_dict\": faf_module.head.state_dict(),\n",
    "                    \"optimizer_head_state_dict\": faf_module.optimizer_head.state_dict(),\n",
    "                    \"scheduler_head_state_dict\": faf_module.scheduler_head.state_dict(),\n",
    "                    \"loss\": running_loss_disp.avg,\n",
    "                }\n",
    "            else:\n",
    "                save_dict = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": faf_module.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": faf_module.optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": faf_module.scheduler.state_dict(),\n",
    "                    \"loss\": running_loss_disp.avg,\n",
    "                }\n",
    "            torch.save(\n",
    "                save_dict, os.path.join(model_save_path, \"epoch_\" + str(epoch) + \".pth\")\n",
    "            )\n",
    "\n",
    "    if need_log:\n",
    "        saver.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--data\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"The path to the preprocessed sparse BEV training data\",\n",
    "    )\n",
    "    parser.add_argument(\"--batch_size\", default=2, type=int, help=\"Batch size\")\n",
    "    parser.add_argument(\"--nepoch\", default=60, type=int, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--nworker\", default=2, type=int, help=\"Number of workers\")\n",
    "    parser.add_argument(\"--lr\", default=0.001, type=float, help=\"Initial learning rate\")\n",
    "    parser.add_argument(\"--log\", default=True, help=\"Whether to log\")\n",
    "    parser.add_argument(\"--logpath\", default=\"./det_reply1\", help=\"The path to the output log file\")\n",
    "    parser.add_argument(\n",
    "        \"--resume\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"The path to the saved model that is loaded to resume training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_teacher\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"The path to the saved teacher model that is loaded to resume training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--layer\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        help=\"Communicate which layer in the single layer com mode\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--warp_flag\", default=0, type=int, help=\"Whether to use pose info for When2com\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--kd_flag\",\n",
    "        default=0,\n",
    "        type=int,\n",
    "        help=\"Whether to enable distillation (only DiscNet is 1 )\",\n",
    "    )\n",
    "    parser.add_argument(\"--kd_weight\", default=100000, type=int, help=\"KD loss weight\")\n",
    "    parser.add_argument(\n",
    "        \"--gnn_iter_times\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        help=\"Number of message passing for V2VNet\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--visualization\", default=True, help=\"Visualize validation result\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--com\",\n",
    "        default=\"v2v\",\n",
    "        type=str,\n",
    "        help=\"lowerbound/upperbound/disco/when2com/v2v/sum/mean/max/cat/agent\",\n",
    "    )\n",
    "    parser.add_argument(\"--rsu\", default=1, type=int, help=\"0: no RSU, 1: RSU\")\n",
    "    parser.add_argument(\n",
    "        \"--num_agent\", default=6, type=int, help=\"The total number of agents\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--auto_resume_path\",\n",
    "        default=\"./det_reply1\",\n",
    "        type=str,\n",
    "        help=\"The path to automatically reload the latest pth\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--compress_level\",\n",
    "        default=0,\n",
    "        type=int,\n",
    "        help=\"Compress the communication layer channels by 2**x times in encoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pose_noise\",\n",
    "        default=0,\n",
    "        type=float,\n",
    "        help=\"draw noise from normal distribution with given mean (in meters), apply to transformation matrix.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--only_v2i\",\n",
    "        default=0,\n",
    "        type=int,\n",
    "        help=\"1: only v2i, 0: v2v and v2i\",\n",
    "    )\n",
    "\n",
    "    torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "    args = parser.parse_args(args=[])\n",
    "    print(args)\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coperception",
   "language": "python",
   "name": "coperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
