{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def ComputeGradient(gradients, curr_losses, mem_losses, gradnorm_mom):\n",
    "    gs = []\n",
    "    for i in range(len(gradients)):  # 对每个任务\n",
    "        g_task_flat = torch.cat([grad.reshape(-1) for grad in gradients[i]], 0)\n",
    "        gs.append(g_task_flat)\n",
    "    tols = ComputeTol(curr_losses, mem_losses, gradnorm_mom)\n",
    "    sol = min_norm_solvers.find_min_norm_element_with_tol(gs, tols)\n",
    "\n",
    "    # if len(gs) > 2:\n",
    "    #     print(3)\n",
    "\n",
    "    d = []\n",
    "    for k in range(len(gradients[0])):\n",
    "        g = 0\n",
    "        for i in range(len(gradients)):  # 对每个任务\n",
    "            g += sol[i] * gradients[i][k] #/ len(gradients)\n",
    "        d.append(g)\n",
    "    return d\n",
    "\n",
    "def ComputeTol(curr_losses, mem_losses, gradnorm_mom):\n",
    "    losses = [torch.from_numpy(mem_losses)] + [torch.from_numpy(loss) for loss in curr_losses] if len(mem_losses) > 0 else [torch.from_numpy(loss) for loss in curr_losses]\n",
    "    tols = []\n",
    "    for k in range(len(losses)):\n",
    "        assert len(losses[k]) > 0\n",
    "        tols.append(gradnorm_mom[k])\n",
    "\n",
    "    tols = torch.tensor(tols, dtype=torch.float64)\n",
    "    tols = softmax(tols/5, 0) # Softmax Temperature 5\n",
    "    return tols\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    x = x - x.max(dim=axis, keepdim=True).values\n",
    "    y = torch.exp(x)\n",
    "    return y / y.sum(dim=axis, keepdim=True)\n",
    "\n",
    "def _projection2simplex_with_tol(y, tols):\n",
    "    \"\"\"\n",
    "    Given y, it solves argmin_z |y-z|_2 st \\sum z = 1 , 1 >= z_i >= 0 for all i\n",
    "    \"\"\"\n",
    "    sorted_idx = torch.flip(torch.argsort(y), dims=[0])\n",
    "    tmpsum = 0.0\n",
    "    tmpsum_tol = 0.0\n",
    "    tmax_f = (torch.sum(torch.mul(y, tols)) - 1.0) / torch.sum(torch.mul(tols, tols))\n",
    "\n",
    "    for i in sorted_idx[:-1]:\n",
    "        tmpsum += y[i] * tols[i]  # plus from large to small\n",
    "        tmpsum_tol += tols[i] * tols[i]  # plus from large to small\n",
    "        tmax = (tmpsum - 1.) / (tmpsum_tol)  #\n",
    "        if tols[i] * tmax > y[i]:  # 基本无法满足条件\n",
    "            tmax_f = tmax\n",
    "            break\n",
    "\n",
    "    output = torch.max(y - tmax_f * tols, torch.zeros_like(y))\n",
    "    return output\n",
    "\n",
    "\n",
    "def _min_norm_2d_with_tol(vecs, dps, tols):\n",
    "    \"\"\"\n",
    "    Find the minimum norm solution as combination of two points\n",
    "    This is correct only in 2D\n",
    "    ie. min_c |\\sum c_i x_i|_2^2 st. \\sum c_i = 1 , 1 >= c_1 >= 0 for all i, c_i + c_j = 1.0 for some i, j\n",
    "    \"\"\"\n",
    "    dmin = None\n",
    "    for i in range(len(vecs)):\n",
    "        for j in range(i + 1, len(vecs)):\n",
    "            if (i, j) not in dps:\n",
    "                dps[(i, j)] = torch.sum(torch.mul(vecs[i].view(-1), vecs[j].view(-1))).item()\n",
    "                dps[(j, i)] = dps[(i, j)]\n",
    "            if (i, i) not in dps:\n",
    "                dps[(i, i)] = torch.sum(torch.mul(vecs[i].view(-1), vecs[i].view(-1))).item()\n",
    "            if (j, j) not in dps:\n",
    "                dps[(j, j)] = torch.sum(torch.mul(vecs[j].view(-1), vecs[j].view(-1))).item()\n",
    "\n",
    "            c, d = _min_norm_element_from2_with_tol_v2(dps[(i, i)], dps[(i, j)], dps[(j, j)], tols[i], tols[j])\n",
    "\n",
    "            if dmin == None:\n",
    "                dmin = d\n",
    "                sol = [(i, j), c, d]\n",
    "            else:\n",
    "                if d < dmin:\n",
    "                    dmin = d\n",
    "                    sol = [(i, j), c, d]\n",
    "    return sol, dps\n",
    "\n",
    "\n",
    "def _next_point_with_tol_v2(cur_val, grad, n, tols, lr):\n",
    "    # proj_grad = grad - ( np.sum(grad) / n ) # 一定下降的方向\n",
    "\n",
    "    next_point = grad * lr + cur_val\n",
    "    # print(cur_val)\n",
    "    # print(next_point)\n",
    "    # print(proj_grad)\n",
    "    # print(t)\n",
    "    # print(t*proj_grad)\n",
    "    # exit()\n",
    "    # _n = next_point\n",
    "    # _n = _projection2simplex_with_tol(next_point, tols)\n",
    "    return next_point\n",
    "\n",
    "\n",
    "def _projection2simplex_with_tol(y, tols):\n",
    "    \"\"\"\n",
    "    Given y, it solves argmin_z |y-z|_2 st \\sum z = 1 , 1 >= z_i >= 0 for all i\n",
    "    \"\"\"\n",
    "    sorted_idx = torch.flip(torch.argsort(y), dim=0)\n",
    "    tmpsum = torch.tensor(0.0)\n",
    "    tmpsum_tol = torch.tensor(0.0)\n",
    "    tmax_f = (torch.sum(torch.mul(y, tols)) - 1.0) / torch.sum(torch.mul(tols, tols))\n",
    "\n",
    "    for i in sorted_idx[:-1]:\n",
    "        tmpsum += y[i] * tols[i]  # plus from large to small\n",
    "        tmpsum_tol += tols[i] * tols[i]  # plus from large to small\n",
    "        tmax = (tmpsum - 1.) / (tmpsum_tol)  #\n",
    "        if tols[i] * tmax > y[i]:  # 基本无法满足条件\n",
    "            tmax_f = tmax\n",
    "            break\n",
    "\n",
    "    output = torch.max(y - tmax_f * tols, torch.zeros_like(y))\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def find_min_norm_element_with_tol(vecs, tols):\n",
    "    dps = {}\n",
    "    init_sol, dps = _min_norm_2d_with_tol(vecs, dps, tols)\n",
    "\n",
    "    n = len(vecs)\n",
    "    iter_count = 0\n",
    "\n",
    "    grad_mat = torch.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            grad_mat[i,j] = dps[(i, j)]\n",
    "    sol_vec = torch.ones([n], dtype=torch.float64) / n\n",
    "    P = grad_mat\n",
    "    A = tols\n",
    "    q = torch.zeros([n], dtype=torch.float64)\n",
    "    b = torch.tensor([1.], dtype=torch.float64)\n",
    "    lb = (1/(n+1))*torch.ones([n], dtype=torch.float64)\n",
    "    sol_vec = torch.optim.solve_qp(P=P, q=q, A=A, b=b, lb=lb, initvals=sol_vec)\n",
    "    lr = 0.001\n",
    "\n",
    "    while iter_count < MAX_ITER:\n",
    "        grad_dir = -1.0*torch.matmul(grad_mat, sol_vec) - 100*(torch.dot(sol_vec, tols) * tols - 1)\n",
    "        print(iter_count, \"- 1 gamma*norm\", torch.matmul(torch.matmul(sol_vec, grad_mat), sol_vec))\n",
    "        new_point = _next_point_with_tol_v2(sol_vec, grad_dir, n, tols, lr)\n",
    "        print(new_point, tols, torch.dot(new_point, tols))\n",
    "        print(iter_count, \"- 2 gamma*norm\", torch.matmul(torch.matmul(new_point, grad_mat), new_point))\n",
    "        new_sol_vec = new_point\n",
    "        change = new_sol_vec - sol_vec\n",
    "        if torch.sum(torch.abs(change)) < STOP_CRIT:\n",
    "            sol_vec =  _projection2simplex_with_tol(sol_vec, tols)\n",
    "            print(sol_vec, tols, torch.dot(sol_vec, tols))\n",
    "            print(iter_count, \"Mapping: gamma*norm\", torch.matmul(torch.matmul(sol_vec, grad_mat), sol_vec))\n",
    "            print('-------------')\n",
    "            return sol_vec\n",
    "        sol_vec = new_sol_vec\n",
    "        iter_count += 1 # delete this line for unlimited optimization\n",
    "    sol_vec =  _projection2simplex_with_tol(sol_vec, tols)\n",
    "    print(iter_count, \"Mapping: gamma*norm\", torch.matmul(torch.matmul(sol_vec, grad_mat), sol_vec))\n",
    "    print('-------------')\n",
    "    return sol_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mem(m,gradients):\n",
    "    q = 0.9\n",
    "    p = 0.1\n",
    "    a = []\n",
    "    for i in range(len(gradients)): \n",
    "        grad_array = np.array(gradients[i])\n",
    "        grad_norm = np.linalg.norm(grad_array)\n",
    "        a.append(q*m[i] +p*grad_norm)\n",
    "    return a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coperception",
   "language": "python",
   "name": "coperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
